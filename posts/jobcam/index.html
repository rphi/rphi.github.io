<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>JobCam - hackathon machine vision project | _rphi</title><meta name=keywords content="projects"><meta name=description content="JobCam was developed as a &ldquo;fun&rdquo; new way to find jobs in your area. It allows you to target your phone at an object, and then through the infojobs API we can find a closely matching job, that will be overlayed. The app processed data in real time allowing the user to move the phone around the room to find interesting jobs that they had not considered.
(yes, the use case is somewhat contrived - if I remember rightly there was a prize for &ldquo;most innovative use of the InfoJobs API&mldr;)"><meta name=author content><link rel=canonical href=https://rphi.uk/posts/jobcam/><link crossorigin=anonymous href=/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.min.4dcb3c4f38462f66c6b6137227726f5543cb934cca9788f041c087e374491df2.js integrity="sha256-Tcs8TzhGL2bGthNyJ3JvVUPLk0zKl4jwQcCH43RJHfI=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://rphi.uk/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=16x16 href=https://rphi.uk/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://rphi.uk/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://rphi.uk/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://rphi.uk/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="JobCam - hackathon machine vision project"><meta property="og:description" content="JobCam was developed as a &ldquo;fun&rdquo; new way to find jobs in your area. It allows you to target your phone at an object, and then through the infojobs API we can find a closely matching job, that will be overlayed. The app processed data in real time allowing the user to move the phone around the room to find interesting jobs that they had not considered.
(yes, the use case is somewhat contrived - if I remember rightly there was a prize for &ldquo;most innovative use of the InfoJobs API&mldr;)"><meta property="og:type" content="article"><meta property="og:url" content="https://rphi.uk/posts/jobcam/"><meta property="og:image" content="https://github.com/rphi/hackupc18/raw/master/logo.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-10-21T00:00:00+00:00"><meta property="article:modified_time" content="2018-10-21T00:00:00+00:00"><meta property="og:site_name" content="_rphi"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://github.com/rphi/hackupc18/raw/master/logo.png"><meta name=twitter:title content="JobCam - hackathon machine vision project"><meta name=twitter:description content="JobCam was developed as a &ldquo;fun&rdquo; new way to find jobs in your area. It allows you to target your phone at an object, and then through the infojobs API we can find a closely matching job, that will be overlayed. The app processed data in real time allowing the user to move the phone around the room to find interesting jobs that they had not considered.
(yes, the use case is somewhat contrived - if I remember rightly there was a prize for &ldquo;most innovative use of the InfoJobs API&mldr;)"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://rphi.uk/posts/"},{"@type":"ListItem","position":2,"name":"JobCam - hackathon machine vision project","item":"https://rphi.uk/posts/jobcam/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"JobCam - hackathon machine vision project","name":"JobCam - hackathon machine vision project","description":"JobCam was developed as a \u0026ldquo;fun\u0026rdquo; new way to find jobs in your area. It allows you to target your phone at an object, and then through the infojobs API we can find a closely matching job, that will be overlayed. The app processed data in real time allowing the user to move the phone around the room to find interesting jobs that they had not considered.\n(yes, the use case is somewhat contrived - if I remember rightly there was a prize for \u0026ldquo;most innovative use of the InfoJobs API\u0026hellip;)","keywords":["projects"],"articleBody":"JobCam was developed as a “fun” new way to find jobs in your area. It allows you to target your phone at an object, and then through the infojobs API we can find a closely matching job, that will be overlayed. The app processed data in real time allowing the user to move the phone around the room to find interesting jobs that they had not considered.\n(yes, the use case is somewhat contrived - if I remember rightly there was a prize for “most innovative use of the InfoJobs API…)\nThe app has two parts, the Object Detection Server, written in C++, which contains an instance of the YOLOv3 neural network, and exposes an HTTP endpoint offering classification of JPG files, and the Android application itself.\nI worked on this alongside my teammates @bnelo12, @kubasz and @qaisjp.\nThe project source (beware, this was developed on minimal sleep!) is on its GitHub repo\n","wordCount":"153","inLanguage":"en","image":"https://github.com/rphi/hackupc18/raw/master/logo.png","datePublished":"2018-10-21T00:00:00Z","dateModified":"2018-10-21T00:00:00Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://rphi.uk/posts/jobcam/"},"publisher":{"@type":"Organization","name":"_rphi","logo":{"@type":"ImageObject","url":"https://rphi.uk/%3Clink%20/%20abs%20url%3E"}}}</script></head><body id=top><script>window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://rphi.uk/ accesskey=h title="_rphi (Alt + H)">_rphi</a>
<span class=logo-switches></span></div><ul id=menu><li><a href=https://rphi.uk/about/ title=about><span>about</span></a></li><li><a href=https://rphi.uk/contact/ title=contact><span>contact</span></a></li><li><a href=https://rphi.uk/tags/projects/ title=projects><span>projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>JobCam - hackathon machine vision project</h1><div class=post-meta><span title="2018-10-21 00:00:00 +0000 UTC">October 21, 2018</span>&nbsp;·&nbsp;1 min</div></header><figure class=entry-cover><img loading=lazy src=https://github.com/rphi/hackupc18/raw/master/logo.png alt></figure><div class=post-content><p>JobCam was developed as a &ldquo;fun&rdquo; new way to find jobs in your area. It allows you to target your phone at an object,
and then through the infojobs API we can find a closely matching job, that will be overlayed. The app processed
data in real time allowing the user to move the phone around the room to find interesting jobs that they had not
considered.</p><p>(yes, the use case is somewhat contrived - if I remember rightly there was a prize for &ldquo;most innovative use of the
InfoJobs API&mldr;)</p><p>The app has two parts, the Object Detection Server, written in C++, which contains an instance of the YOLOv3
neural network, and exposes an HTTP endpoint offering classification of JPG files, and the Android application
itself.</p><p>I worked on this alongside my teammates @bnelo12, @kubasz and @qaisjp.</p><p>The project source (beware, this was developed on minimal sleep!) is on its <a href=https://github.com/rphi/hackupc18/>GitHub repo</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://rphi.uk/tags/projects/>projects</a></li></ul><nav class=paginav><a class=prev href=https://rphi.uk/posts/coinz/><span class=title>« Prev Page</span><br><span>Coinz - location based mobile game</span></a>
<a class=next href=https://rphi.uk/posts/democrapp/><span class=title>Next Page »</span><br><span>DemocrApp - the Democracy App</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2022 <a href=https://rphi.uk/>_rphi</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(t){t.preventDefault();var e=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(e)}']`).scrollIntoView({behavior:"smooth"}),e==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${e}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(t=>{const n=t.parentNode.parentNode,e=document.createElement("button");e.classList.add("copy-code"),e.innerText="copy";function s(){e.innerText="copied!",setTimeout(()=>{e.innerText="copy"},2e3)}e.addEventListener("click",o=>{if("clipboard"in navigator){navigator.clipboard.writeText(t.textContent),s();return}const e=document.createRange();e.selectNodeContents(t);const n=window.getSelection();n.removeAllRanges(),n.addRange(e);try{document.execCommand("copy"),s()}catch(e){}n.removeRange(e)}),n.classList.contains("highlight")?n.appendChild(e):n.parentNode.firstChild==n||(t.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?t.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(e):t.parentNode.appendChild(e))})</script></body></html>